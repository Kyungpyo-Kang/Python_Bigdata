{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# day05_04_crawling\n",
    "- 원하는 데이터 수집하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- python에서 크롤링을 하기 위해 필요한 외부 패키지를 import 한다.\n",
    "- bs4 모듈 안에 있는 BeautifulSoup 패키지를 import한다.\n",
    "- Soup은 일종의 통신 방식이다.\n",
    "- 모듈이란?\n",
    "- 여러 패키지들을 그룹화 해놓은 것과 비슷한 느낌이라고 생각하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 대상사이트 : 아파치\n",
    "- https://www.apache.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_url = 'https://www.apache.org/'\n",
    "# 2. 아파치 재단에서 관리하는 프로젝트 목록을 긁어온다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 대상사이트에 페이지 요청하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get요청에 따른 response 200이면 성공\n",
    "# 404 -> 페이지 없음\n",
    "reponse = req.get(target_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  응답된 결과를 담은 response변수에서 페이지의 내용 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response.text를 BeautifulSoup에 넣어줌으로써, html 스럽게 변환(파싱)한다.\n",
    "soup = BeautifulSoup(reponse.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. html 결과 값에서 긁어올 부분(카테고리) select하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# div 태그의 자식레벨에 있는 ul 태그를 가져오기\n",
    "# ul 태그의 자식레벨에 있는 li 태그를 가져오기\n",
    "# li 태그의 자식레벨에 있는 a 태그를 가져오기\n",
    "categories = soup.select('#by_category>ul>li>a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# categories를 반복문을 통해서 순회하기\n",
    "- 반복문을 돌면서 a태그를 제외한 텍스트만을 가져온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview\n",
      "All Projects\n",
      "Attic\n",
      "Big Data\n",
      "Build Management\n",
      "Cloud\n",
      "Content\n",
      "Databases\n",
      "FTP\n",
      "Graphics\n",
      "HTTP\n",
      "HTTP-module\n",
      "Incubating\n",
      "JavaEE\n",
      "Labs\n",
      "Libraries\n",
      "Mail\n",
      "Mobile\n",
      "Network-client\n",
      "Network-server\n",
      "OSGi\n",
      "RegExp\n",
      "Retired\n",
      "Search\n",
      "Security\n",
      "SQL\n",
      "Testing\n",
      "Virtual-machine\n",
      "Web-framework\n",
      "XML\n"
     ]
    }
   ],
   "source": [
    "for category in categories:\n",
    "    print(category.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## soup 변수를 이용하여 by_name의 프로젝트에 관한 url을 크롤링 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://httpd.apache.org/\n",
      "http://accumulo.apache.org/\n",
      "http://activemq.apache.org/\n",
      "http://airavata.apache.org/\n",
      "http://airflow.apache.org/\n",
      "http://allura.apache.org/\n",
      "http://ambari.apache.org/\n",
      "http://ant.apache.org/\n",
      "http://any23.apache.org/\n",
      "http://archiva.apache.org/\n",
      "http://aries.apache.org/\n",
      "http://arrow.apache.org/\n",
      "http://asterixdb.apache.org/\n",
      "http://atlas.apache.org/\n",
      "http://attic.apache.org/\n",
      "http://avro.apache.org/\n",
      "http://axis.apache.org/\n",
      "http://bahir.apache.org/\n",
      "http://beam.apache.org/\n",
      "http://bigtop.apache.org/\n",
      "http://bloodhound.apache.org/\n",
      "http://bookkeeper.apache.org/\n",
      "http://brooklyn.apache.org/\n",
      "http://buildr.apache.org/\n",
      "http://bval.apache.org/\n",
      "http://calcite.apache.org/\n",
      "http://camel.apache.org/\n",
      "http://carbondata.apache.org/\n",
      "http://cassandra.apache.org/\n",
      "http://cayenne.apache.org/\n",
      "http://celix.apache.org/\n",
      "http://chemistry.apache.org/\n",
      "http://chukwa.apache.org/\n",
      "http://clerezza.apache.org/\n",
      "http://cloudstack.apache.org/\n",
      "http://cocoon.apache.org/\n",
      "http://commons.apache.org/\n",
      "http://community.apache.org/\n",
      "http://cordova.apache.org/\n",
      "http://couchdb.apache.org/\n",
      "http://creadur.apache.org/\n",
      "http://crunch.apache.org/\n",
      "http://ctakes.apache.org/\n",
      "http://curator.apache.org/\n",
      "http://cxf.apache.org/\n",
      "http://datafu.apache.org/\n",
      "http://db.apache.org/\n",
      "http://deltaspike.apache.org/\n",
      "http://directory.apache.org/\n",
      "http://drat.apache.org/\n",
      "http://drill.apache.org/\n",
      "http://druid.apache.org\n",
      "http://dubbo.apache.org/\n",
      "http://eagle.apache.org/\n",
      "http://empire-db.apache.org/\n",
      "http://felix.apache.org/\n",
      "http://fineract.apache.org/\n",
      "http://flex.apache.org/\n",
      "http://flink.apache.org/\n",
      "http://flume.apache.org/\n",
      "http://fluo.apache.org/\n",
      "http://freemarker.apache.org/\n",
      "http://geode.apache.org/\n",
      "http://geronimo.apache.org/\n",
      "http://giraph.apache.org/\n",
      "http://gora.apache.org/\n",
      "http://griffin.apache.org/\n",
      "http://groovy.apache.org/\n",
      "http://guacamole.apache.org/\n",
      "http://gump.apache.org/\n",
      "http://hadoop.apache.org/\n",
      "http://hawq.apache.org/\n",
      "http://hbase.apache.org/\n",
      "http://helix.apache.org/\n",
      "http://hive.apache.org/\n",
      "http://hc.apache.org/\n",
      "http://ignite.apache.org/\n",
      "http://impala.apache.org/\n",
      "http://incubator.apache.org/\n",
      "http://isis.apache.org/\n",
      "http://jackrabbit.apache.org/\n",
      "http://james.apache.org/\n",
      "http://jclouds.apache.org/\n",
      "http://jena.apache.org/\n",
      "http://jmeter.apache.org/\n",
      "http://johnzon.apache.org/\n",
      "http://joshua.apache.org/\n",
      "http://jspwiki.apache.org/\n",
      "http://juddi.apache.org/\n",
      "http://juneau.apache.org/\n",
      "http://kafka.apache.org/\n",
      "http://karaf.apache.org/\n",
      "http://kibble.apache.org/\n",
      "http://knox.apache.org/\n",
      "http://kudu.apache.org/\n",
      "http://kylin.apache.org/\n",
      "http://labs.apache.org/\n",
      "http://lens.apache.org/\n",
      "http://libcloud.apache.org/\n",
      "http://logging.apache.org/\n",
      "http://lucene.apache.org/\n",
      "http://lucenenet.apache.org/\n",
      "http://madlib.apache.org/\n",
      "http://mahout.apache.org/\n",
      "http://manifoldcf.apache.org/\n",
      "http://marmotta.apache.org/\n",
      "http://maven.apache.org/\n",
      "http://mesos.apache.org/\n",
      "http://metamodel.apache.org/\n",
      "http://metron.apache.org/\n",
      "http://mina.apache.org/\n",
      "http://mnemonic.apache.org/\n",
      "http://myfaces.apache.org/\n",
      "http://mynewt.apache.org/\n",
      "http://netbeans.apache.org/\n",
      "http://nifi.apache.org/\n",
      "http://nutch.apache.org/\n",
      "http://ofbiz.apache.org/\n",
      "http://olingo.apache.org/\n",
      "http://oodt.apache.org/\n",
      "http://oozie.apache.org/\n",
      "http://climate.apache.org/\n",
      "http://openjpa.apache.org/\n",
      "http://openmeetings.apache.org/\n",
      "http://opennlp.apache.org/\n",
      "http://openoffice.apache.org/\n",
      "http://openwebbeans.apache.org/\n",
      "http://openwhisk.apache.org/\n",
      "http://orc.apache.org/\n",
      "http://parquet.apache.org/\n",
      "http://pdfbox.apache.org/\n",
      "http://perl.apache.org/\n",
      "http://petri.apache.org\n",
      "http://phoenix.apache.org/\n",
      "http://pig.apache.org/\n",
      "http://pivot.apache.org/\n",
      "http://plc4x.apache.org/\n",
      "http://poi.apache.org/\n",
      "http://apr.apache.org/\n",
      "http://portals.apache.org/\n",
      "http://predictionio.apache.org/\n",
      "http://pulsar.apache.org/\n",
      "http://qpid.apache.org/\n",
      "http://ranger.apache.org/\n",
      "http://reef.apache.org/\n",
      "http://river.apache.org/\n",
      "http://rocketmq.apache.org/\n",
      "http://roller.apache.org/\n",
      "http://royale.apache.org/\n",
      "http://rya.apache.org/\n",
      "http://samza.apache.org/\n",
      "http://santuario.apache.org/\n",
      "http://sentry.apache.org/\n",
      "http://serf.apache.org/\n",
      "http://servicecomb.apache.org/\n",
      "http://servicemix.apache.org/\n",
      "http://shardingsphere.apache.org\n",
      "http://shiro.apache.org/\n",
      "http://singa.apache.org/\n",
      "http://sis.apache.org/\n",
      "http://skywalking.apache.org/\n",
      "http://sling.apache.org/\n",
      "http://spamassassin.apache.org/\n",
      "http://spark.apache.org/\n",
      "http://sqoop.apache.org/\n",
      "http://steve.apache.org/\n",
      "http://storm.apache.org/\n",
      "http://streams.apache.org/\n",
      "http://struts.apache.org/\n",
      "http://submarine.apache.org/\n",
      "http://subversion.apache.org/\n",
      "http://synapse.apache.org/\n",
      "http://syncope.apache.org/\n",
      "http://systemml.apache.org/\n",
      "http://tajo.apache.org/\n",
      "http://tapestry.apache.org/\n",
      "http://tcl.apache.org/\n",
      "http://tez.apache.org/\n",
      "http://thrift.apache.org/\n",
      "http://tika.apache.org/\n",
      "http://tinkerpop.apache.org/\n",
      "http://tomcat.apache.org/\n",
      "http://tomee.apache.org/\n",
      "http://trafficcontrol.apache.org/\n",
      "http://trafficserver.apache.org/\n",
      "http://trafodion.apache.org/\n",
      "http://turbine.apache.org/\n",
      "http://twill.apache.org/\n",
      "http://uima.apache.org/\n",
      "http://unomi.apache.org/\n",
      "http://usergrid.apache.org/\n",
      "http://vcl.apache.org/\n",
      "http://velocity.apache.org/\n",
      "http://ws.apache.org/\n",
      "http://whimsical.apache.org/\n",
      "http://wicket.apache.org/\n",
      "http://xalan.apache.org/\n",
      "http://xerces.apache.org/\n",
      "http://xmlgraphics.apache.org/\n",
      "http://yetus.apache.org/\n",
      "http://zeppelin.apache.org/\n",
      "http://zookeeper.apache.org/\n"
     ]
    }
   ],
   "source": [
    "names = soup.select('#by_name>div>div>div>ul>li>a')\n",
    "for name in names: \n",
    "    print(name.attrs['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a 태그 안의 주소로 들어가기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://httpd.apache.org/'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# names[0].attrs을 찍어보면 자료형이 딕셔너리임을 알 수 있다.\n",
    "# names[0].attrs의 키값('href')으로 해당 url(value)에 접근한다.\n",
    "names[0].attrs['href']\n",
    "# names[0].attrs['href']의 결과는 url\n",
    "# 해당 url을 다시 req.get에 넘겨주면 다시 크롤링을 할 수 있다.\n",
    "# 이러한 방식으로 계속 타고타고 들어가서 크롤링을 할 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
